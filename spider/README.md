可以从功能将爬虫分成静态爬虫和动态爬虫，因为爬虫本质就是类似浏览器一样的发请求收回答，所以很多网络库可以实现爬虫的功能，当然大部分都是静态爬虫，如果想使用动态爬虫，就需要新的库，当然动态爬虫也有不好的地方，就是性能，如果场景是大量的静态爬虫，就可以考虑通过并发去加速，虽然Python因为GIL的存在是假的多线程，但是爬虫中的并发模型是IO密集型的，在等待网络回复中花费了大量时间，所以这时就有并发的必要性了。  
爬虫除了爬取，还有对网页内容的解析。

+ `request`：用于静态爬虫，简单
+ `aiohttp`：使用协程，用于静态爬虫，性能高
+ `selenuim`：用于动态爬虫，但是需要浏览器驱动器
<!-- + `playwright`：用于动态爬虫，无头浏览器 -->

+ `bs4`：网页解析库
